{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Clusterização: K-means e Hierárquico\n",
        "\n",
        "Este notebook executa o pré-processamento (sem a coluna de rótulo), aplica K-means e Clusterização Hierárquica com diferentes `linkage`, avalia K-means via método do cotovelo para escolha de K, e compara os resultados entre algoritmos usando métricas de clusterização.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurações gerais\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 120)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carregamento e preparação dos dados (sem rótulo)\n",
        "\n",
        "Substitua `data/arquivo.csv` e ajuste a coluna do rótulo `target` para removê-la do `X` antes da clusterização.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Leitura\n",
        "csv_path = '../data/arquivo.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "TARGET_COL = 'target'  # ajuste se necessário\n",
        "X = df.drop(columns=[TARGET_COL]) if TARGET_COL in df.columns else df.copy()\n",
        "\n",
        "# Inferência de tipos\n",
        "feature_cols = X.columns.tolist()\n",
        "dtypes = X.dtypes\n",
        "numeric_features = dtypes[dtypes.kind in 'iufc'].index.tolist()\n",
        "categorical_features = [c for c in feature_cols if c not in numeric_features]\n",
        "\n",
        "print('Numéricas:', numeric_features)\n",
        "print('Categóricas:', categorical_features)\n",
        "print('Shape X:', X.shape)\n",
        "X.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento: imputação e escala / one-hot\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler(with_mean=True, with_std=True))\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features),\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "X_proc = preprocess.fit_transform(X)\n",
        "print('Shape X processado:', X_proc.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Método do cotovelo para K-means\n",
        "\n",
        "Calcula o SSE (inertia) para vários valores de K e seleciona-se o K no \"cotovelo\" do gráfico. Em seguida, roda-se K-means com esse K. Também computaremos métricas de qualidade de clusterização: Silhouette, Calinski-Harabasz e Davies-Bouldin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Teste do cotovelo\n",
        "K_MIN, K_MAX = 2, 12\n",
        "inertias = []\n",
        "Ks = list(range(K_MIN, K_MAX + 1))\n",
        "for k in Ks:\n",
        "    km = KMeans(n_clusters=k, n_init=10, random_state=RANDOM_STATE)\n",
        "    km.fit(X_proc)\n",
        "    inertias.append(km.inertia_)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(Ks, inertias, marker='o')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Inertia (SSE)')\n",
        "plt.title('Método do Cotovelo - KMeans')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Escolha do K: ajuste manualmente com base no cotovelo\n",
        "K_CHOSEN = 4  # ajuste após visualizar o gráfico\n",
        "print('K escolhido:', K_CHOSEN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KMeans com K escolhido\n",
        "kmeans = KMeans(n_clusters=K_CHOSEN, n_init=10, random_state=RANDOM_STATE)\n",
        "labels_kmeans = kmeans.fit_predict(X_proc)\n",
        "\n",
        "sil_km = silhouette_score(X_proc, labels_kmeans)\n",
        "ch_km = calinski_harabasz_score(X_proc, labels_kmeans)\n",
        "db_km = davies_bouldin_score(X_proc, labels_kmeans)\n",
        "\n",
        "print(f'Silhouette (KMeans): {sil_km:.4f}')\n",
        "print(f'Calinski-Harabasz (KMeans): {ch_km:.2f}')\n",
        "print(f'Davies-Bouldin (KMeans): {db_km:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clusterização Hierárquica\n",
        "\n",
        "Rodaremos `AgglomerativeClustering` com o mesmo K escolhido no cotovelo e variaremos dois métodos de linkage (por exemplo, `ward` e `complete`), comparando as métricas com o K-means.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def avaliar_clusterizacao(labels, nome):\n",
        "    sil = silhouette_score(X_proc, labels)\n",
        "    ch = calinski_harabasz_score(X_proc, labels)\n",
        "    db = davies_bouldin_score(X_proc, labels)\n",
        "    print(f\"\\n{nome}\")\n",
        "    print(f\"Silhouette: {sil:.4f}\")\n",
        "    print(f\"Calinski-Harabasz: {ch:.2f}\")\n",
        "    print(f\"Davies-Bouldin: {db:.4f}\")\n",
        "\n",
        "# Dois linkages para comparar\n",
        "for linkage in ['ward', 'complete']:\n",
        "    # 'ward' requer métrica euclidiana\n",
        "    if linkage == 'ward':\n",
        "        model = AgglomerativeClustering(n_clusters=K_CHOSEN, linkage=linkage)\n",
        "    else:\n",
        "        model = AgglomerativeClustering(n_clusters=K_CHOSEN, linkage=linkage, metric='euclidean')\n",
        "\n",
        "    labels_hier = model.fit_predict(X_proc)\n",
        "    avaliar_clusterizacao(labels_hier, f'Hierárquico ({linkage})')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparação e Métrica Própria\n",
        "\n",
        "Além das métricas clássicas, podemos adotar uma métrica composta simples para ranquear as soluções: maximize `silhouette` e `calinski-harabasz`, minimize `davies-bouldin`. Uma proposta: score = z(silhouette) + z(calinski) - z(davies). Abaixo, exemplificamos como calcular e comparar para K-means e Hierárquico.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler as _Std\n",
        "\n",
        "# Coletar métricas\n",
        "results = []\n",
        "results.append({'alg':'KMeans', 'sil': sil_km, 'ch': ch_km, 'db': db_km})\n",
        "\n",
        "# Recalcular para hierárquicos com os mesmos linkages para registrar\n",
        "scores_hier = {}\n",
        "for linkage in ['ward', 'complete']:\n",
        "    if linkage == 'ward':\n",
        "        model = AgglomerativeClustering(n_clusters=K_CHOSEN, linkage=linkage)\n",
        "    else:\n",
        "        model = AgglomerativeClustering(n_clusters=K_CHOSEN, linkage=linkage, metric='euclidean')\n",
        "    labels = model.fit_predict(X_proc)\n",
        "    scores_hier[linkage] = {\n",
        "        'sil': silhouette_score(X_proc, labels),\n",
        "        'ch': calinski_harabasz_score(X_proc, labels),\n",
        "        'db': davies_bouldin_score(X_proc, labels)\n",
        "    }\n",
        "    results.append({'alg': f'Hier({linkage})', **scores_hier[linkage]})\n",
        "\n",
        "# Score composto (z-normalizado)\n",
        "df_res = pd.DataFrame(results)\n",
        "scaler = _Std()\n",
        "z_sil = scaler.fit_transform(df_res[['sil']]).ravel()\n",
        "z_ch  = scaler.fit_transform(df_res[['ch']]).ravel()\n",
        "z_db  = scaler.fit_transform(df_res[['db']]).ravel()\n",
        "\n",
        "df_res['score_composto'] = z_sil + z_ch - z_db\n",
        "print(df_res.sort_values('score_composto', ascending=False))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
