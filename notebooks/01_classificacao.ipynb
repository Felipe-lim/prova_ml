{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Classificação com Validação Cruzada Estratificada\n",
        "\n",
        "Este notebook realiza o pré-processamento, separação de atributos/rótulos e avaliação de três algoritmos supervisionados:\n",
        "- Árvore de Decisão (Random Forest)\n",
        "- K-NN (K-Nearest Neighbors)\n",
        "- MLP (Multi-Layer Perceptron)\n",
        "\n",
        "A avaliação utiliza F1-score e matriz de confusão via validação cruzada estratificada k-fold, com `random_state` fixo para reprodutibilidade.\n",
        "\n",
        "Observação: Ajuste o caminho do arquivo da base de dados na seção de carregamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurações gerais\n",
        "RANDOM_STATE = 42\n",
        "N_JOBS = -1\n",
        "N_SPLITS = 5  # k-fold\n",
        "\n",
        "# Exibição de opções do pandas\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 120)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate, cross_val_predict\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carregamento de dados\n",
        "\n",
        "Substitua `data/arquivo.csv` pelo caminho real. O rótulo (target) deve estar em uma coluna, por exemplo `target`. Se a base tiver valores ausentes, faremos tratamento na etapa de pré-processamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Leitura da base\n",
        "# ATENÇÃO: ajuste o caminho abaixo para o arquivo correto\n",
        "csv_path = '../data/arquivo.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pré-processamento\n",
        "\n",
        "- Identificação de colunas numéricas e categóricas\n",
        "- Tratamento de valores ausentes\n",
        "- Padronização de numéricas e One-Hot em categóricas\n",
        "- Separação de `X` e `y`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inferir colunas numéricas e categóricas automaticamente (exclui a coluna alvo)\n",
        "TARGET_COL = 'target'  # ajuste o nome aqui\n",
        "\n",
        "# Checa se a coluna alvo existe\n",
        "assert TARGET_COL in df.columns, f\"Coluna alvo '{TARGET_COL}' não encontrada no DataFrame.\"\n",
        "\n",
        "feature_cols = [c for c in df.columns if c != TARGET_COL]\n",
        "\n",
        "dtypes = df[feature_cols].dtypes\n",
        "numeric_features = dtypes[dtypes.kind in 'iufc'].index.tolist()\n",
        "categorical_features = [c for c in feature_cols if c not in numeric_features]\n",
        "\n",
        "print('Numéricas:', numeric_features)\n",
        "print('Categóricas:', categorical_features)\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y = df[TARGET_COL].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformações: imputação + escala/one-hot\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler(with_mean=True, with_std=True))\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features),\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Validação cruzada estratificada k-fold\n",
        "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
        "scorer = {'f1_macro': make_scorer(f1_score, average='macro')}\n",
        "\n",
        "print(preprocess)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelagem e Avaliação (CV Estratificada)\n",
        "\n",
        "Treinaremos e avaliaremos:\n",
        "- Random Forest\n",
        "- KNN\n",
        "- MLP\n",
        "\n",
        "Usaremos F1 macro e exibiremos a matriz de confusão a partir de `cross_val_predict` para cada modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def avaliar_modelo(nome, estimator):\n",
        "    pipe = Pipeline(steps=[('preprocess', preprocess), ('model', estimator)])\n",
        "    # cross_validate para f1 macro\n",
        "    cv_results = cross_validate(\n",
        "        pipe, X, y, cv=cv, scoring=scorer, n_jobs=N_JOBS, return_estimator=False, error_score='raise'\n",
        "    )\n",
        "\n",
        "    # cross_val_predict para matriz de confusão\n",
        "    y_pred = cross_val_predict(pipe, X, y, cv=cv, n_jobs=N_JOBS, method='predict')\n",
        "\n",
        "    f1_mean = np.mean(cv_results['test_f1_macro'])\n",
        "    f1_std = np.std(cv_results['test_f1_macro'])\n",
        "\n",
        "    print(f\"\\nModelo: {nome}\")\n",
        "    print(f\"F1-macro (média ± std): {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot(cmap='Blues', values_format='d')\n",
        "    plt.title(f'Matriz de Confusão - {nome}')\n",
        "    plt.show()\n",
        "\n",
        "# Modelos com hiperparâmetros básicos e random_state fixo\n",
        "rf = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
        "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=RANDOM_STATE)\n",
        "\n",
        "for nome, est in [\n",
        "    ('Random Forest', rf),\n",
        "    ('KNN', knn),\n",
        "    ('MLP', mlp)\n",
        "]:\n",
        "    avaliar_modelo(nome, est)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
